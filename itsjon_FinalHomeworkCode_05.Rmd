---
title: "itsjon_FinalHomeworkCode_05"
author: "Jonathan Zhang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
```

**Bootstrapping Standard Errors and CIs for Linear Models**

```{r}
# Load data
library(curl) # curl the data
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
data <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)

# Create log-transformed variables
data$logHR <- log(data$HomeRange_km2)
data$logBM <- log(data$Body_mass_female_mean)

# Fit linear model
model <- lm(logHR ~ logBM, data = data)

# View coefficients
summary(model)$coefficients
```
-The Summary of the model produces an  intercept of -9.44123 and slope of 1.03643.

*Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.*

```{r}
set.seed(1234)  # for reproducibility
n_boot <- 1000
boot_coefs <- replicate(n_boot, {
  boot_sample <- data[sample(1:nrow(data), replace = TRUE), ]
  coef(lm(logHR ~ logBM, data = boot_sample))
})

# Transpose for easier handling
boot_coefs <- t(boot_coefs)
colnames(boot_coefs) <- c("Intercept", "Slope")

# Estimate SE and CI
boot_se <- apply(boot_coefs, 2, sd)
boot_ci <- apply(boot_coefs, 2, quantile, probs = c(0.025, 0.975))

# Display results
boot_se
boot_ci
```

```{r}
# Full model SEs
full_se <- summary(model)$coefficients[, "Std. Error"]

# Full model CIs
confint(model)

# Comparison
comparison <- data.frame(
  Coefficient = c("Intercept", "Slope"),
  Full_SE = full_se,
  Bootstrap_SE = boot_se,
  Full_CI_Low = confint(model)[,1],
  Full_CI_High = confint(model)[,2],
  Boot_CI_Low = boot_ci[1, ],
  Boot_CI_High = boot_ci[2, ]
)
comparison
```
## To answer the question: How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?
The standard errors estimated using bootstrapping were very similar to the formula used directly from the lm() function. I think it means the assumptions of the linear model are not being severely violated, and that the formula-based SEs can be reasonably reliable in this case. The slight differences can occur still, due to the random effect in the resampling process, especially if the dataset contains any outliers or is not very large.
## How does the latter compare to the 95% CI estimated from your entire dataset?
The 95% confidence intervals estimated via bootstrapping were generally slightly wider than the ones estimated by the standard lm() method. Since bootstrapping does not assume a particular sampling distribution (like normality) and makes more of the variability in the data. I think it is especially useful in cases where the model assumptions may not hold, making bootstrap CIs more robust. That said, in this case, the bootstrap and model-based CIs largely overlapped, indicating consistency between methods.

**EXTRA CREDIT FUNCTION**

```{r}
# This function performs bootstrap inference for any linear model
bootstrap_lm <- function(d, m, conf.level = 0.95, n = 1000) {
  f <- as.formula(m)
  full_model <- lm(f, data = d)
  full_summary <- summary(full_model)
  full_ci <- confint(full_model, level = conf.level) # This should fit the model on the full dataset
# Now to create a bootstrap loop
  coefs <- replicate(n, {
    boot_sample <- d[sample(1:nrow(d), replace = TRUE), ]
    coef(lm(f, data = boot_sample))
  })
  coefs <- t(coefs)
# Calculate means, SEs, and CIs from the bootstrap samples
  boot_means <- colMeans(coefs)
  boot_se <- apply(coefs, 2, sd)
  alpha <- (1 - conf.level) / 2
  boot_ci <- apply(coefs, 2, quantile, probs = c(alpha, 1 - alpha))
# Finally, combine everything into a summary dataframe
  result <- data.frame(
    Coefficient = names(coef(full_model)),
    Full_Estimate = coef(full_model),
    Full_SE = full_summary$coefficients[, "Std. Error"],
    Full_CI_Low = full_ci[, 1],
    Full_CI_High = full_ci[, 2],
    Boot_Mean = boot_means,
    Boot_SE = boot_se,
    Boot_CI_Low = boot_ci[1, ],
    Boot_CI_High = boot_ci[2, ]
  )
  return(result)
}

# Run it
bootstrap_lm(data, "logHR ~ logBM")
```

**EXTRA EXTRA CREDIT: Graphs Over Increasing Bootstraps**

```{r}
library(ggplot2)
```

```{r}
# Created a function to track how coefficient estimates stabilize as n increases
bootstrap_curve <- function(d, m, max_n = 200, step = 10) {
  f <- as.formula(m)
  full_model <- lm(f, data = d)
  beta_vals <- coef(full_model)
  results <- data.frame()
  for (n in seq(10, max_n, by = step)) {
    coefs <- replicate(n, {
      boot_sample <- d[sample(1:nrow(d), replace = TRUE), ]
      coef(lm(f, data = boot_sample))
    })
    coefs <- t(coefs)
    ci <- apply(coefs, 2, quantile, probs = c(0.025, 0.975))
    means <- colMeans(coefs)
# Get means and CIs
 for (i in 1:length(means)) {
      results <- rbind(results, data.frame(
        Coefficient = names(means)[i],
        N = n,
        Mean = means[i],
        CI_Low = ci[1, i],
        CI_High = ci[2, i],
        Full_Beta = beta_vals[i]
      ))
    }
  }
  return(results)
}

# Run the curve function
boot_plot_data <- bootstrap_curve(data, "logHR ~ logBM")

# Plot
bootplot_graph <- ggplot(boot_plot_data, aes(x = N)) +
  geom_line(aes(y = Mean, color = Coefficient)) +
  geom_ribbon(aes(ymin = CI_Low, ymax = CI_High, fill = Coefficient), alpha = 0.2) +
  geom_hline(aes(yintercept = Full_Beta, color = Coefficient), linetype = "dashed") +
  labs(title = "Bootstrapped Beta Estimates vs. Number of Resamples",
       y = "Beta Value", x = "Number of Bootstraps") +
  theme_minimal(base_size = 14)
bootplot_graph
```
