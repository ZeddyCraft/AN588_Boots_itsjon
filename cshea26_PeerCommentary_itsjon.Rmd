---
title: "itsjon_OriginalHomeworkCode_04"
author: "Jonathan Zhang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
```

**Bootstrapping Standard Errors and CIs for Linear Models**

```{r}
# Load data
data <- read.csv("C:/Users/Richard/Desktop/AN588RStudio/KamilarAndCooperData.csv")

# Create log-transformed variables
data$logHR <- log(data$HomeRange_km2)
data$logBM <- log(data$Body_mass_female_mean)

# Fit linear model
model <- lm(logHR ~ logBM, data = data)

# View coefficients
summary(model)$coefficients
```

> Carly: I really like how you used the summary function to pull this data to view the coeffients; it's much simpler and more direct than how I pulled a summary of specific columns for the coefficients
> One suggestion I have for the sake of this assignment and data analayis is to provide a summary or reflection of how these values compare. I talked about how they're both very similar given that they follow the assumptions of linear regression. Whatever you say it may be helpful for others reviewing this code to understand what's going on!

*Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.*

```{r}
set.seed(123)  # for reproducibility
n_boot <- 1000
boot_coefs <- replicate(n_boot, {
  boot_sample <- data[sample(1:nrow(data), replace = TRUE), ]
  coef(lm(logHR ~ logBM, data = boot_sample))
})

# Transpose for easier handling
boot_coefs <- t(boot_coefs)
colnames(boot_coefs) <- c("Intercept", "Slope")

# Estimate SE and CI
boot_se <- apply(boot_coefs, 2, sd)
boot_ci <- apply(boot_coefs, 2, quantile, probs = c(0.025, 0.975))

# Display results
boot_se
boot_ci
```
> Carly Great work using the set seed function for reproducibility 
- I noticed our 95% CI's are similar but not identical for this portion. I realized here that I should probably use a similar method of creating CIs based on how you used boot.ci(), rather than relying on confint(lm()) since that is dependent on the data meeting all linear regression assumptions. I will change this in my own assignment. 


```{r}
# Full model SEs
full_se <- summary(model)$coefficients[, "Std. Error"]

# Full model CIs
confint(model)

# Comparison
comparison <- data.frame(
  Coefficient = c("Intercept", "Slope"),
  Full_SE = round(full_se, 4),
  Bootstrap_SE = boot_se,
  Full_CI_Low = confint(model)[,1],
  Full_CI_High = confint(model)[,2],
  Boot_CI_Low = boot_ci[1, ],
  Boot_CI_High = boot_ci[2, ]
)
comparison
```
> Carly: Great comparison! Could also use the round() function to cut off the decimals you have here if you wanted to. I did an example for just the Full_SE portion above.


**EXTRA CREDIT FUNCTION**

```{r}
bootstrap_lm <- function(d, m, conf.level = 0.95, n = 1000) {
  f <- as.formula(m)
  full_model <- lm(f, data = d)
  full_summary <- summary(full_model)
  full_ci <- confint(full_model, level = conf.level)
  
  coefs <- replicate(n, {
    boot_sample <- d[sample(1:nrow(d), replace = TRUE), ]
    coef(lm(f, data = boot_sample))
  })
  
  coefs <- t(coefs)
  boot_means <- colMeans(coefs)
  boot_se <- apply(coefs, 2, sd)
  alpha <- (1 - conf.level) / 2
  boot_ci <- apply(coefs, 2, quantile, probs = c(alpha, 1 - alpha))
  
  result <- data.frame(
    Coefficient = names(coef(full_model)),
    Full_Estimate = coef(full_model),
    Full_SE = full_summary$coefficients[, "Std. Error"],
    Full_CI_Low = full_ci[, 1],
    Full_CI_High = full_ci[, 2],
    Boot_Mean = boot_means,
    Boot_SE = boot_se,
    Boot_CI_Low = boot_ci[1, ],
    Boot_CI_High = boot_ci[2, ]
  )
  return(result)
}

# Example usage
bootstrap_lm(data, "logHR ~ logBM")
```
> Carly: Overall, very well done! One suggestion would be adding on to your comments within the chunks of text to provide more context as to what you are doing. Same advice as above with using the round() function.

**EXTRA EXTRA CREDIT: Graphs Over Increasing Bootstraps**

```{r}
library(ggplot2)
```

```{r}
bootstrap_curve <- function(d, m, max_n = 200, step = 10) {
  f <- as.formula(m)
  full_model <- lm(f, data = d)
  beta_vals <- coef(full_model)
  
  results <- data.frame()
  
  for (n in seq(10, max_n, by = step)) {
    coefs <- replicate(n, {
      boot_sample <- d[sample(1:nrow(d), replace = TRUE), ]
      coef(lm(f, data = boot_sample))
    })
    coefs <- t(coefs)
    ci <- apply(coefs, 2, quantile, probs = c(0.025, 0.975))
    means <- colMeans(coefs)
    
    for (i in 1:length(means)) {
      results <- rbind(results, data.frame(
        Coefficient = names(means)[i],
        N = n,
        Mean = means[i],
        CI_Low = ci[1, i],
        CI_High = ci[2, i],
        Full_Beta = beta_vals[i]
      ))
    }
  }
  return(results)
}

# Run the curve generator
boot_plot_data <- bootstrap_curve(data, "logHR ~ logBM")

# Plot
bootplot_graph <- ggplot(boot_plot_data, aes(x = N)) +
  geom_line(aes(y = Mean, color = Coefficient)) +
  geom_ribbon(aes(ymin = CI_Low, ymax = CI_High, fill = Coefficient), alpha = 0.2) +
  geom_hline(aes(yintercept = Full_Beta, color = Coefficient), linetype = "dashed") +
  labs(title = "Bootstrapped Beta Estimates vs. Number of Resamples",
       y = "Beta Value", x = "Number of Bootstraps") +
  theme_minimal(base_size = 14)
bootplot_graph
```
> Carly: Overall your code looks great and everything runs smoothly. The way that you went about creating the bootstrap_lm() function was great for your extra credit section - it's super scalable and very clean! It makes me want to go back for the final assignment to try attempting these portions. The code overall is very concise and clear - one suggestion I had throughout was to provide more commentary to outline what you are doing, also to decribe whats going on with the data and results you derive by using the summary() functions. I provided these three bullets in HW 5 from Dr. Schmitt that I just pasted and answered directly in my document: 
- How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?
- How does the latter compare to the 95% CI estimated from your entire dataset?

> Carly: Hope this was helpful! Feel free to reach out if you have any follow up questions!